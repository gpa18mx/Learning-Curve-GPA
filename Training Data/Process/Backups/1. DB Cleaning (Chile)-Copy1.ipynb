{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadexcel(x):#, #y = 'Sheet1'): \n",
    "    run = True\n",
    "    file= pd.ExcelFile(x)\n",
    "    names = file.sheet_names\n",
    "    names = re.sub(\"'\",'', str(names))\n",
    "    print (\"This file contains this tab names:\", names )\n",
    "    while run is True:\n",
    "        try:\n",
    "            decision = (input(\"Choose your tab name? \"))\n",
    "            print (\"Your choice is\", decision)\n",
    "            confirm = int(input(\"This is correct? Please write 1 for yes or 2 for no \"))\n",
    "            if confirm == 1:\n",
    "                print (\"Processing Tab, please wait\")\n",
    "                final_file = file.parse(decision)\n",
    "                return final_file\n",
    "                run = False\n",
    "            else:\n",
    "                print ('Choose the right tab!') \n",
    "        except Exception as e:\n",
    "            print (\"There is an error: \", e)\n",
    "            print (\"Please Try Again! :)\")\n",
    "            continue\n",
    "            \n",
    "def loading_excel():\n",
    "    x = input('\\033[94m'+'Please write your file location: ' +'\\033[0m')\n",
    "    real_x = path.realpath(x)\n",
    "    doc = loadexcel(real_x) \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import re #regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write your file location: C:\\Users\\Gpardo\\Desktop\\Clasification\\DB\\Import pc - tablet abril %2c may Q2 2018.xlsx\n",
      "This file contains this tab names: [PersonalizadoImp (22)]\n",
      "Choose your tab name? PersonalizadoImp (22)\n",
      "Your choice is PersonalizadoImp (22)\n",
      "This is correct? Please write 1 for yes or 2 for no 1\n",
      "Processing Tab, please wait\n"
     ]
    }
   ],
   "source": [
    "today_db = loading_excel()\n",
    "today_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rut_Importador</th>\n",
       "      <th>Nombre_Importador</th>\n",
       "      <th>Arancel</th>\n",
       "      <th>Descripcion_Arancel</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Marca</th>\n",
       "      <th>Variedad</th>\n",
       "      <th>Atributo_3</th>\n",
       "      <th>Atributo_4</th>\n",
       "      <th>Atributo_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Fecha_inf_Importacion</th>\n",
       "      <th>Cuenta_Advalorem</th>\n",
       "      <th>Monto_Advalorem</th>\n",
       "      <th>Porcentaje_Advalorem</th>\n",
       "      <th>Codigo_Advalorem</th>\n",
       "      <th>Cuenta_Advalorem.1</th>\n",
       "      <th>Monto_Cuenta_178_IVA</th>\n",
       "      <th>Total_Giro_US</th>\n",
       "      <th>Numero_Manifiesto_1</th>\n",
       "      <th>Numero_Manifiesto_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84713010</td>\n",
       "      <td>DE PESO INFERIOR O IGUAL A 1 K</td>\n",
       "      <td>TABLET PC</td>\n",
       "      <td>MASTER-G</td>\n",
       "      <td>SENSE701B</td>\n",
       "      <td>MAQUINA AUTOMATICAS PARA PROCE</td>\n",
       "      <td>SAMIENTO DE DATOS,PORTATIL,PES</td>\n",
       "      <td>O INFERIOR A 10 KILOS.</td>\n",
       "      <td>...</td>\n",
       "      <td>2500-01-01 00:00:00</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Derechos ad valorem</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27024.82</td>\n",
       "      <td>27025.22</td>\n",
       "      <td>167228</td>\n",
       "      <td>167228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84713010</td>\n",
       "      <td>DE PESO INFERIOR O IGUAL A 1 K</td>\n",
       "      <td>TABLET PC</td>\n",
       "      <td>MASTER-G</td>\n",
       "      <td>SENSE701B</td>\n",
       "      <td>MAQUINA AUTOMATICAS PARA PROCE</td>\n",
       "      <td>SAMIENTO DE DATOS,PORTATIL,PES</td>\n",
       "      <td>O INFERIOR A 10 KILOS.</td>\n",
       "      <td>...</td>\n",
       "      <td>2500-01-01 00:00:00</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Derechos ad valorem</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1351.24</td>\n",
       "      <td>1351.24</td>\n",
       "      <td>167228</td>\n",
       "      <td>167228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84713020</td>\n",
       "      <td>DE PESO SUPERIOR A 1 KG PERO I</td>\n",
       "      <td>NOTE-BOOKS- USADO ANO 2017</td>\n",
       "      <td>LENOVO</td>\n",
       "      <td>20HF0011US/SERIAL/PC0RXYS-</td>\n",
       "      <td>APARATO DE PESO INF. A 2C KIL</td>\n",
       "      <td>OS PARA EL TRATAMIENTO DE DATO</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>2500-01-01 00:00:00</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Derechos ad valorem</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.17</td>\n",
       "      <td>260.30</td>\n",
       "      <td>231046</td>\n",
       "      <td>231046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84713010</td>\n",
       "      <td>DE PESO INFERIOR O IGUAL A 1 K</td>\n",
       "      <td>ORDENADORES (TABLETS)</td>\n",
       "      <td>MLAB</td>\n",
       "      <td>TIPO TABLETAS, 8GB</td>\n",
       "      <td>MAQUINAS AUTOMATICAS PARATRAT</td>\n",
       "      <td>AMIENTO O PROCESAMIENTODE DATO</td>\n",
       "      <td>S, PORTATILES</td>\n",
       "      <td>...</td>\n",
       "      <td>2500-01-01 00:00:00</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Derechos ad valorem</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.31</td>\n",
       "      <td>176.31</td>\n",
       "      <td>165928</td>\n",
       "      <td>165928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84713010</td>\n",
       "      <td>DE PESO INFERIOR O IGUAL A 1 K</td>\n",
       "      <td>ORDENADORES TABLETS</td>\n",
       "      <td>PGX</td>\n",
       "      <td>ZEHN</td>\n",
       "      <td>PORTATILES, PARA PROCESAMIENTO</td>\n",
       "      <td>S DE DATOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2500-01-01 00:00:00</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Derechos ad valorem</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6056.68</td>\n",
       "      <td>6056.68</td>\n",
       "      <td>165928</td>\n",
       "      <td>165928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rut_Importador Nombre_Importador   Arancel             Descripcion_Arancel  \\\n",
       "0           1935               NaN  84713010  DE PESO INFERIOR O IGUAL A 1 K   \n",
       "1           1935               NaN  84713010  DE PESO INFERIOR O IGUAL A 1 K   \n",
       "2           2202               NaN  84713020  DE PESO SUPERIOR A 1 KG PERO I   \n",
       "3           6114               NaN  84713010  DE PESO INFERIOR O IGUAL A 1 K   \n",
       "4           6114               NaN  84713010  DE PESO INFERIOR O IGUAL A 1 K   \n",
       "\n",
       "                       Nombre     Marca                    Variedad  \\\n",
       "0                   TABLET PC  MASTER-G                   SENSE701B   \n",
       "1                   TABLET PC  MASTER-G                   SENSE701B   \n",
       "2  NOTE-BOOKS- USADO ANO 2017    LENOVO  20HF0011US/SERIAL/PC0RXYS-   \n",
       "3       ORDENADORES (TABLETS)      MLAB          TIPO TABLETAS, 8GB   \n",
       "4         ORDENADORES TABLETS       PGX                        ZEHN   \n",
       "\n",
       "                       Atributo_3                      Atributo_4  \\\n",
       "0  MAQUINA AUTOMATICAS PARA PROCE  SAMIENTO DE DATOS,PORTATIL,PES   \n",
       "1  MAQUINA AUTOMATICAS PARA PROCE  SAMIENTO DE DATOS,PORTATIL,PES   \n",
       "2   APARATO DE PESO INF. A 2C KIL  OS PARA EL TRATAMIENTO DE DATO   \n",
       "3   MAQUINAS AUTOMATICAS PARATRAT  AMIENTO O PROCESAMIENTODE DATO   \n",
       "4  PORTATILES, PARA PROCESAMIENTO                      S DE DATOS   \n",
       "\n",
       "               Atributo_5         ...          Fecha_inf_Importacion  \\\n",
       "0  O INFERIOR A 10 KILOS.         ...            2500-01-01 00:00:00   \n",
       "1  O INFERIOR A 10 KILOS.         ...            2500-01-01 00:00:00   \n",
       "2                       S         ...            2500-01-01 00:00:00   \n",
       "3           S, PORTATILES         ...            2500-01-01 00:00:00   \n",
       "4                     NaN         ...            2500-01-01 00:00:00   \n",
       "\n",
       "   Cuenta_Advalorem Monto_Advalorem Porcentaje_Advalorem     Codigo_Advalorem  \\\n",
       "0               223             0.0                    0  Derechos ad valorem   \n",
       "1               223             0.0                    0  Derechos ad valorem   \n",
       "2               223             0.0                    0  Derechos ad valorem   \n",
       "3               223             0.0                    0  Derechos ad valorem   \n",
       "4               223             0.0                    0  Derechos ad valorem   \n",
       "\n",
       "   Cuenta_Advalorem.1  Monto_Cuenta_178_IVA  Total_Giro_US  \\\n",
       "0                 0.0              27024.82       27025.22   \n",
       "1                 0.0               1351.24        1351.24   \n",
       "2                 0.0                252.17         260.30   \n",
       "3                 0.0                176.31         176.31   \n",
       "4                 0.0               6056.68        6056.68   \n",
       "\n",
       "   Numero_Manifiesto_1  Numero_Manifiesto_2  \n",
       "0               167228               167228  \n",
       "1               167228               167228  \n",
       "2               231046               231046  \n",
       "3               165928               165928  \n",
       "4               165928               165928  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_db = loading_excel()\n",
    "\n",
    "#C:\\Users\\Gpardo\\Desktop\\Clasification\\Marzo.xlsx\n",
    "#C:\\Users\\Gpardo\\Desktop\\Consumption\\Python Projects\\Imports\\Chile\\Historical FIles\\Historical Imports.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergefield(x, jo=\"\"):\n",
    "    bold = \"\\033[1m\"\n",
    "    end =  \"\\033[0m\"\n",
    "    GREEN = '\\033[92m'\n",
    "    i=-1\n",
    "    names = list(x)\n",
    "    b = dict(enumerate(names))\n",
    "    print (\"This file contains this columns:\" )\n",
    "    for name in names:\n",
    "        i=i+1\n",
    "        print(str(i)+\".\"+\" \"+ name)\n",
    "    print (bold+GREEN+\"Choose the columns you want to merge.\"+end)\n",
    "    election = input().split(\",\")\n",
    "    item = list(map(int, election))\n",
    "    convert = [b[y] for y in item]\n",
    "    print(\"Your Choice is\", convert)\n",
    "    stripped = x[convert].fillna('').apply(lambda x: x.str.strip())\n",
    "    join_symb = jo\n",
    "    stripped = stripped.astype(str).apply(join_symb.join, axis=1)\n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_db['Merged'] = mergefield (hist_db)\n",
    "hist_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_chile(x, sign=\"~\", num_col= 4, col = ['ID Aduanal','Descripcion', 'Marca', \"Modelo\", \"Caracteristicas\"]):\n",
    "    bold = \"\\033[1m\"\n",
    "    end =  \"\\033[0m\"\n",
    "    print(bold+\"Choose the Column you want to split\"+end)\n",
    "    i=-1\n",
    "    names = list(x)\n",
    "    b = dict(enumerate(names))\n",
    "    print (\"This file contains this columns:\" )\n",
    "    print (\"Given The list, choose the numbers of the columns.\")\n",
    "    for name in names:\n",
    "        i=i+1\n",
    "        print(str(i)+\".\"+\" \"+ str(name))\n",
    "    election = input().split(\",\")\n",
    "    item = list(map(int, election))\n",
    "    convert = [b[y] for y in item]\n",
    "    print(\"Your Choice is\", convert)\n",
    "    df = x[convert]\n",
    "    my_dict = {}\n",
    "    a=-1\n",
    "    for k in convert:\n",
    "        a=a+1\n",
    "        my_dict[k] = \"value\"+str(a)\n",
    "    df = df.rename(columns=my_dict)\n",
    "    clean = '(\\s|)'+str(sign)+'(\\s|)'\n",
    "    clean2= str(sign)+'+'\n",
    "    df['value0'] = df['value0'].replace(r'\\s+',' ')\n",
    "    df['value0'] = df['value0'].replace(clean,sign)\n",
    "    df['value0'] = df['value0'].replace(clean2,sign)\n",
    "    df['value0'] = df['value0'].str.strip()\n",
    "    columns_name = col\n",
    "    list_col = list(col)\n",
    "    \n",
    "    print(columns_name)\n",
    "    df2 = pd.DataFrame(df['value0'].str.split(sign,num_col).tolist(), columns = columns_name)\n",
    "    df = pd.concat([x,df2], axis=1)\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(r'\\s\\s+',' ')\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(clean,\"\")\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].replace(clean2,\"\")\n",
    "    df.iloc[:,-1] = df.iloc[:,-1].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_db_expand = split_chile(hist_db)\n",
    "hist_db_expand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_db_expand.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_db_expand = hist_db_expand[['Timescale','Merged', 'ID Aduanal', 'Descripcion', 'Marca',\n",
    "       'Modelo', 'Caracteristicas', 'Processed', 'Vendor',\n",
    "       'Product', 'Model Name']]\n",
    "hist_db_expand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_words = loading_excel() #type words\n",
    "Codes = loading_excel() #Words Final\n",
    "#C:\\Users\\Gpardo\\Desktop\\Consumption\\Python Projects\\Imports\\Chile\\Base\\Final Words.xlsx\n",
    "\n",
    "Codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = Codes['Remove'].dropna().str.replace(\"\\(\",\"\").str.replace(\"\\\\\",\"\").str.replace('\\.',\"\",case=False).str.replace('\\s\\s+',\" \",case=False).str.strip().tolist()\n",
    "batch1mod = Codes['Codes'].dropna().str.replace(\"\\.\",\" \",case=False).str.replace(\"\\-F\",\"\",case=False).str.replace('\\s\\s+',\" \",case=False).str.strip().tolist()\n",
    "batch2mod = Codes['Codes_comp'].dropna().str.replace(\"\\.\",\" \",case=False).str.replace(\"\\-F\",\"\",case=False).str.replace('\\s\\s+',\" \",case=False).str.strip().unique().tolist()\n",
    "remove_words\n",
    "batch2mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_words = \"|\".join(remove_words)\n",
    "batch1mod = \"|\".join(batch1mod)\n",
    "batch2mod = \"|\".join(batch2mod)\n",
    "print(remove_words)\n",
    "print(batch1mod)\n",
    "print(batch2mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_comp=['ESA-F']\n",
    "list_comp = \"|\".join(list_comp)\n",
    "\n",
    "\n",
    "hist_db_expand['Test Vendors_1'] = hist_db_expand['Descripcion'].str.findall(list_comp).str[0]\n",
    "hist_db_expand['Descripcion_Clean'] = hist_db_expand['Descripcion'].str.replace(list_comp ,\"\")\n",
    "# Remove 2nd Batch\n",
    "hist_db_expand['Descripcion_Clean'] = hist_db_expand['Descripcion_Clean'].str.replace(\"\\.\",\" \",case=False).str.replace(\"\\-F\",\"\",case=False).str.replace(\"\\s\\s+\",\" \")\n",
    "hist_db_expand['Test Vendors_2'] = hist_db_expand['Descripcion_Clean'].str.findall(batch1mod).str[0]\n",
    "hist_db_expand['Descripcion_Clean'] = hist_db_expand['Descripcion_Clean'].str.replace(batch1mod ,\"\")\n",
    "#clean\n",
    "hist_db_expand['Descripcion_Clean'] = hist_db_expand['Descripcion_Clean'].str.replace(remove_words,\"\",case=False)\n",
    "hist_db_expand['Descripcion_Clean'] = hist_db_expand['Descripcion_Clean'].str.strip()\n",
    "\n",
    "# Remove 3rd Batch\n",
    "hist_db_expand['Test Vendors_3'] = hist_db_expand['Descripcion_Clean'].str.findall(batch2mod).str[0]\n",
    "hist_db_expand['Descripcion_Clean'] = hist_db_expand['Descripcion_Clean'].str.replace(batch2mod ,\"\")\n",
    "#clean\n",
    "\n",
    "hist_db_expand.iloc[2840]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_words = loading_excel() #type words\n",
    "#C:\\Users\\Gpardo\\Desktop\\Consumption\\Python Projects\\Imports\\Chile\\Base\\Final Words.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_words_final = dict_words[~dict_words['Status'].str.upper().str.contains(\"GOOD|CHECK\")]#.iloc[:,-1]\n",
    "dict_words_final = dict_words_final[dict_words_final.columns[:-1]]\n",
    "corrections = dict_words_final.set_index(\"Word\")['Status'].to_dict()\n",
    "print(len(corrections))\n",
    "corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_words_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_db_expand_test = hist_db_expand.copy()\n",
    "hist_db_expand_test.replace({\"Descripcion_Clean\": corrections}, inplace=True)\n",
    "hist_db_expand_test.iloc[5440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_db_expand_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_db_expand_test['Test Vendors'] = hist_db_expand_test['Test Vendors_2'].fillna(hist_db_expand_test['Test Vendors_2'])\n",
    "hist_db_expand_test['Test Vendors'] = hist_db_expand_test['Test Vendors'].fillna(hist_db_expand_test['Test Vendors_3'])\n",
    "hist_db_expand_test['Test Vendors'] = hist_db_expand_test['Test Vendors'].fillna(hist_db_expand_test['Marca'])\n",
    "hist_db_expand_test = hist_db_expand_test[['Timescale', 'Merged', 'ID Aduanal', 'Descripcion', 'Marca', 'Modelo',\n",
    "       'Caracteristicas', 'Processed', 'Vendor', 'Product', 'Model Name', 'Descripcion_Clean', 'Test Vendors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = ['GALAXY']\n",
    "mod1 = \"|\".join(mod1)\n",
    "hist_db_expand_test['Modelo_1'] = hist_db_expand_test['Descripcion_Clean'].str.findall(mod1).str[0]\n",
    "hist_db_expand_test['Descripcion_Clean'] = hist_db_expand_test['Descripcion_Clean'].str.replace(mod1 ,\"\",case=False)\n",
    "hist_db_expand_test['Descripcion_Clean']=hist_db_expand_test['Descripcion_Clean'].str.strip()\n",
    "hist_db_expand_test['Modelo_1'] = hist_db_expand_test['Modelo_1'].fillna(hist_db_expand_test['Modelo'])\n",
    "\n",
    "hist_db_expand_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_db_expand_test['Descripcion_Clean'] = hist_db_expand_test['Descripcion_Clean'].str.replace(\"\\W\",\" \",case=False).str.replace(\"\\s\\s+\",\" \",case=False).str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_db_expand_test['Test Vendors'] = hist_db_expand_test['Test Vendors'].str.replace(\"\\-F\",\"\").str.strip(\".\")\n",
    "hist_db_expand_test[\"Model ID\"] = hist_db_expand_test[\"ID Aduanal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting DB in Model & Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_db_expand = hist_db_expand_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_db_expand = hist_db_expand_test.copy()\n",
    "models = hist_db_expand[hist_db_expand['Processed'].str.contains('Model|model|check')]\n",
    "trash = hist_db_expand[~hist_db_expand['Processed'].str.contains('Model|model|check')]\n",
    "models['Processed'].unique()\n",
    "trash['Processed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_search =[\"P7P69LT\", \"M738R\", \"I86\", \"L3T78EP\", \"MTK8127\",\"A62178\", \n",
    "                \"X9R21EC\", \"M839R\", \"TAB A\",\"2EM32UP\", \"2QU23EP\", \"2QU23EP\", \n",
    "                \"HSTNN-C78C\", \"ST907\", \"M738R\", \"1000G2\", \"OZ-06860\", \"YT3-X90F\",\n",
    "                \"ZA0R0020CL\", \"Y4A39AA-ABM\", \"Y4A39AA-ABM\", \"T5H16EP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"MODELO(|S)\",\"\", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"NZAA\",\"\", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"PRO\",\" PRO \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"\\, O VARIEDAD\\:\",\"\", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"SAMSUNG\",\"\", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"PTO\",\" PRO \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"TAB\",\" TAB\", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"TIPO\",\" \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(r\"(\\w{3})ACHO|(\\w{3})ACH0|(\\w{3})AHO|(\\w{3})UCHO\",\" \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"NDWUCHO\",\" NDWUCHO \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"MOD\\.|MOD\",\" \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"GETAC\",\" GETAC \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"MTK8127\",\" MTK8127 \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"MARCA\\:\",\"\", case= False)        \n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"MAZON\\.COM\\-F\",\"AMAZON.COM\", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.replace(\"\\s\\s+\",\" \", case= False)\n",
    "models[\"Modelo_1\"] = models[\"Modelo_1\"].str.strip()\n",
    "\n",
    "models\n",
    "\n",
    "#models[models['Modelo_1'].str.contains(\"TABLET(|S)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_words = loading_excel() #C:\\Users\\Gpardo\\Desktop\\Consumption\\Python Projects\\Imports\\Chile\\Final\\final modelos.xlsx\n",
    "cleaning_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_words['Merged'] = cleaning_words ['check'].astype(str) + \"$\"\n",
    "cleaning_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_model = \"|\".join(cleaning_words['Merged'].tolist())\n",
    "models[\"Modelo_check\"] = models[\"Modelo_1\"].str.replace(delete_model,\" \", case= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.iloc[256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "trash_out = r'C:\\Users\\Gpardo\\Desktop\\Consumption\\Python Projects\\Imports\\Chile\\Final\\DB Cleaning_test'\n",
    "save = datetime.datetime.now().strftime(\"%y_%m_%d\")\n",
    "dir = trash_out +\"_\"+str(save)+\".xlsx\"\n",
    "print(dir)\n",
    "\n",
    "writer = pd.ExcelWriter(dir, engine='xlsxwriter')\n",
    "\n",
    "#Convert the dataframe to an XlsxWriter Excel object.\n",
    "#models.to_excel(writer, sheet_name='Models')\n",
    "#trash.to_excel(writer, sheet_name='Trash')\n",
    "#trash.to_excel(writer, sheet_name='Trash')\n",
    "#models.to_excel(writer, sheet_name='Modelo')\n",
    "hist_db_expand_test.to_excel(writer, sheet_name='Final')\n",
    "\n",
    "#codes_finaldb1.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
